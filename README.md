

# FsChat

Yet another GPT API client library.

**FsChat** focuses on interactivity: 
It shows you real time straming responses as they arrive and renders Markdown and Mermaid diagrams.

## Usage: 1,2,3,4

1) Register for an account and get an API key with OpenAI, TogetherAI, Groq or LeptonAI.

3) Write your key it in `.env` file.

```bash
# example .env file
OPENAI_API_KEY="<your-openai-api-key-here>"
TOGETHERAI_API_KEY=...
GROQ_API_KEY=...
LEPTON_API_KEY=...
```
3) Load **FsChat**:  
- if you're writing a command line **.fsx** script or a normal **.fsproj** project, then load `FsChat`,
- if you're using Dotnet Interactive (Polyglot) notebooks, then load `FsChat.Interactive` package.    


```fsharp
#r "nuget: FsChat.Interactive, 0.0.1"
#r "nuget: dotenv.net, 3.2.0"
open dotenv.net
DotEnv.Load(DotEnvOptions(envFilePaths=[ ".env" ]))
open FsChat
```
4) Choose a GPT model and start a chat session:
```fsharp
let chat = Chat(Gpt4o_mini)
chat.send [
    System """
        You're a helpful assistant that renders responses in Markdown.
        Don't include politeness phrases or excuses at the beginning of responses,
        skip directly to content.
    """
    User """
        Who were the winners of Eurovision contest since 2010?
        Mark any occasion when the contest wasn't held with "N/A" + reason.

        Start response with a short title,
        add a line explaining who was the most recent winner,
        then render a table consisting of following columns:
        | Year | Country | Artist | Song title |
    """
]
```
If you've loaded FsChat.Interactive into a Dotnet Interactive (Polyglot) notebook session,
then you will see live Markdown text previews:

![fschat-table](https://github.com/user-attachments/assets/773eb721-0d6f-4026-b2b6-15be9c743a78)



### Mermaid charts

You can also ask it to render the above table as a Mermaid chart:
````fsharp
chat.model <- Gpt4o // switch to a more powerful model for this task; Gpt4_mini is not very good at rendering charts
chat.send """
    Given the above table, render a Mermaid directed graph with:
    - nodes: countries that won the contest (labeled with country name)
    - edges: time sequence of wins representing how the 'trophy' moved from one country to another (labeled with year)

    Example:

    ```mermaid
    %%{init: {'theme': 'default', 'themeVariables': { 'fontSize': '10px' }}}%%
    graph LR
        DK[Denmark]
        AT[Austria]
        DK -->|2014| AT
    ```

    Make sure each country appears exactly once in the graph:
    if a country won the competition multiple times, then the country's node should have multiple incoming and outgoing edges.
"""
````
Rule of thumb: you'll get better results, if you give it an example of chart code structure.
![fschat-chart](https://github.com/user-attachments/assets/0ba9a21d-1694-4299-a99b-9e36d9aa2498)

## Agent interaction

The result of each call to `chat.send` is a `Response` record with:
- `text: string` containing the response generated by GPT,
- `result: Result<status*statistics, error_text>` some response metadata.


### Context 
Each chat has a `chat.context` whis is a history of interactions with the GPT:
```fsharp
chat.context = [
    System    "You're a helpful assistant"
    User      "Say a random number"
    Assistant "Sure! How about 42?"
    User      "Why did you say 42?"
    Assistant "Because it’s “the answer to the ultimate question of life, the universe, and everything”"
]
```


Context can be accessed using the `chat.context` property (it returns a list of previous interactions)
or overwritten with `chat.setContext` method.

Context can also be cleared with `chat.clear()` or alternatively you can delete just the last interaction (your last prompt plus GPT's result) with `chat.undo()`.


### Multiple agents example
Here's an example of instatiating two agents and playing a 20 questions game betweeen them.

```fsharp
let agent1 = Chat(model=Gpt4o_mini, context=[
    System """
        You're playing the 20 questions game.
        Your role is to ask 'Is it a ...' questions with Yes-or-No answers
        in order to narrow down your options and guess the word.
        ----
        Hint: You're guessing an animal.
    """
  ])

let agent2 = Chat(model=Gpt4o_mini, context=[
    System """
        You're playing the 20 questions game.
        Your role is the one who thinks of a word and responds to my questions
        with simple "yes" or "no" answers (no additional text)
        Once I guess the correct word, respond with “CORRECT.”
        ----
        The word I'll be trying to guess is: parrot.
    """
])

let rec play timesLeft (text:string) =
    if timesLeft=0 then
        printfn "Game over"
    else
        let quess = agent1.send(text).text
        let assess = agent2.send(quess).text
        if assess.Contains "CORRECT." then
            ()
        else
            play (timesLeft-1) assess

play 20 "I have a word! Which word is it? Ask the first question."
```

![fschat-dialog](https://github.com/user-attachments/assets/b5f6f9e8-bf75-4ea8-9d3f-74addfca4331)

The above animation contains some fancy HTML/CSS formatting. Look at example [dialog.ipynb](docs/dialog.ipynb) for more details and read about how to customize live output rendering below.

## Choosing what kind of live output do you want to see

There is an interface called `IChatRenderer` with three implementations:
- `StdoutRenderer()` is the default for **FsChat** and renders live outputs to console.
- `NotebookRenderer()` is the default for **FsChat.Interactive** and renders live outputs as HTML to Dotnet Interactive (Polyglot) notebooks.
- `NoRenderer()` is a dummy renderer that doesn't output anything (use that if you're writing apps).

There are multiple ways of specifying a renderer:
```fsharp
// passing it as a parameter to Chat constructor
let chat = Chat(Gpt4o_mini, renderer=StdoutRenderer())

// setting it as a property of a Chat instance
chat.setRenderer(StdoutRenderer())

// or setting it globally
Chat.defaultRenderer <- StdoutRenderer()

// If set globally, all new Chat instances will use this renderer.

// `#r FsChat.Interactive` sets it to NotebookRenderer() by default
// otherwise it defaults to StdoutRenderer().
```

### Customizing the NotebookRenderer

NotebookRenderer accepts a few optional parameters:
- `props` a string with HTML tag attributes that will be added to the output div element,
- `css` a string containing CSS stylesheet that will be injected into html.

As a rule of thumb, think of `props` and `css` being inserted into HTML as follows:
```html
<div class='chat-response'>
    {{css}}
    <div {{props}}>
        <p>GPT rendered Markdown response</p>
    </div>
</div>
```
As you can see, `css` should contain HTML code, e.g.
- `<style>...</style>` tag, or
- `<link rel='stylesheet' href='...'>`.



#### Example
```fsharp
let greenHeaderRenderer = NotebookRenderer(
    props="class='my-class'",
    css="<style>.my-class th { color: #080; }</style>"
)
let chat = Chat(Gpt4o, renderer=greenHeaderRenderer)
```
![image](https://github.com/user-attachments/assets/5a2ffa11-7960-484f-a11e-433aaf6b625e)


Have a look at [dialog.ipynb](docs/dialog.ipynb) for sample code.


# Problems

Dotnet.Interactive (Polyglot) notebooks inside Visual Studio Code don't load rendered content correctly:  
notebooks when loaded may (will?) lose rendered content.

(Can someone test if full Visual Studio behaves any better?)


# TODO
- [ ] improve GptModel configuration
  - [ ] simplify customization
- [ ] make Mermaid diagrams smaller
- [x] record examples
- [x] add README
- [ ] make Mermaid dark-mode friendly
- [ ] extract code snippets from markdown frames
- [ ] add API token limit
- [ ] parse tables
- [ ] parse jsons
- [ ] render json schemas
- [ ] add `prompt` notebook kernel




